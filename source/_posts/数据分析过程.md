---
title: 每周导学-第六周-数据分析过程
categories:
  - DAND-VIP
tags:
  - lesson guide
  - pandas
abbrlink: d2468ca4
date: 2018-08-19 05:30:09
---

> Build a dream and the dream will build you.

Hi，同学们，上一阶段我们学习了Python的基础知识，简单了解了Python数据分析的关键库——Pandas，并且通过项目二的实战，相信大家也一定信心满满的准备学习更多的Pandas知识了吧！那么从今天开始未来的四周内，我们将会对Pandas进行更细致的学习，大家加油吧!

本周开始，我们就进入到了**项目三(P3)阶段**，本阶段总共包含**四周**，在这一个月内，我们要对**数据分析入门**进行学习，学习数据分析思维，掌握Python数据分析及可视化方法，并使用所学知识完成**项目三：探索数据集**，尝试着自己完成整个数据分析的流程，得到一些饶有兴趣的结论，你一定会非常有成就感哒！那么以下便是这四周的学习安排：

| 时间      | 学习重点           | 对应课程                     |
| --------- | ------------------ | ---------------------------- |
| **第1周** | **数据分析过程-1** | **数据分析过程&案例研究-1**  |
| 第2周     | 数据分析过程-2     | 案例研究-1&案例研究-2        |
| 第3周     | 完成项目           | 项目：探索数据集             |
| 第4周     | 项目修改与通过     | 修改项目、查缺补漏、休息调整 |

<font size = '3' color = 'red'>！！看这里！！：在P3课程里面安排了SQL的高阶课程，但是因为在项目三中并不会涉及到SQL知识，所以为了保证大家学习的连贯性，在完成前两周的课程之后，就开始项目。至于！！SQL的高阶知识，大家可以放在课程通关后进行选修！！； </font>

本阶段可能是个挑战，请一定要**保持自信**，请一定要坚持**学习和总结**，如果遇到任何**课程问题**请参照如下顺序进行解决：

- 先自行查找问题答案（注意提取关键词），参考：谷歌/百度搜索、[菜鸟教程](http://www.runoob.com/python3/python3-tutorial.html)、[CSDN](https://www.csdn.net/)、[stack**overflow**](https://stackoverflow.com/)、[**Python for Data Analysis, 2nd Edition** ](https://github.com/CapAllen/DAND_VIP_Class/blob/master/%E6%8B%93%E5%B1%95%E5%8F%82%E8%80%83/Python%20for%20Data%20Analysis%2C%202nd%20Edition.pdf)、[Python Cookbook](http://python3-cookbook.readthedocs.io/zh_CN/latest/)
- 若问题未解决，请将**问题**及其**所在课程章节**发送至微信群，并@助教即可

饭要一口一口吃，路要一步一步走，大家不要被任务吓到，跟着导学一步一步来，肯定没问题哒！那我们开始吧！

> **注：**本着**按需知情**原则，所涉及的知识点都是在数据分析过程中必须的、常用的，而不是最全面的，想要更丰富，那就需要你们课下再进一步的学习和探索！

# 本周目标

- 学习课程中**数据分析过程**中的全部和**案例研究1**的部分内容，了解数据分析过程，熟练掌握Pandas在数据分析中的应用。

# 学习计划

| 时间       | 学习资源            | 学习内容                |
| ---------- | ------------------- | ----------------------- |
| 周二       | 微信群 - 每周导学   | 预览每周导学            |
| 周三、周四 | Udacity - Classroom | 数据分析过程&案例研究-1 |
| 周五       | 微信/Classin - 1V1  | 课程难点                |
| 周六       | Classin - 优达日    | 本周学习总结、答疑      |
| 周日       | 笔记本              | 总结沉淀                |
| 周一       | 自主学习            | 查漏补缺                |

# 本周知识清单

## 前期准备&拓展

- 在**课程概述**给出的链接很重要，希望大家能抽空都看一看，尤其是最后的书Python for Data Analysis，目前已经出了第二版，可以戳[下载链接](https://github.com/CapAllen/DAND_VIP_Class/blob/master/%E6%8B%93%E5%B1%95%E5%8F%82%E8%80%83/Python%20for%20Data%20Analysis%2C%202nd%20Edition.pdf)进行下载。
- 关于**设置编程环境**，本章已经不是建议了，而是**要求**，如果你还没有完成本地环境的配置，请戳：[配置Anaconda和Jupyter Notebook](https://classroom.udacity.com/nanodegrees/nd002-cn-basic-vip/parts/e566ad37-6119-4448-a6bc-7ade73ef3992)

## 数据分析流程

**数据分析不是从上至下一蹴而就的过程，而是需要你不断迭代、重复、完善，最终得到结论的过程。**

### 提出问题

- 数据集中的各个变量之间的相关性如何？是否存在某些联系？

- 变量的统计结果会揭示什么？

- 根据现有掌握的数据，能否对未来走势进行预测？

- 根据你想了解的问题，去收集数据，再对问题进行修缮，如此**迭代**，获取更全面的数据，提出更一阵见血的问题。

  ...

### 整理数据

- 收集

  数据库提取？直接下载？网络爬虫？

- 评估

  这个过程是对数据产生直观印象的过程，你要尝试了解数据集的大小，基本的统计结果，是否存在数据重复？缺失？数据类型是否正确？是否每个变量成一列&每个观察值成一行？数据是否有统计错误？(严重偏离正常值，比如说气温达到70℃等等)...

- 清理

  对评估出的问题进行逐项排查、清理，直至获取到干净的数据（推荐超级有用且经典的[Tidy Data](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html)，虽然代码用的是R语言，但代码不就只是工具而已嘛，关键的是**思维方法**）

### 探索性数据分析

即课程中提到的EDA(Exploratory data analysis )，这是一种分析数据集——尤其是陌生数据集——的方法，具体实施的话可以采用定量、定性的数据分析或者是可视化分析。

这是一个强调**迭代**的过程，在这个阶段你要不断的对数据进行探索（提问、整理、分析、可视化等等），根据你得到的结果再去丰富你的数据或者完善你的问题，最终得出结论。

这是一个考验耐心和细心的繁琐过程，所以一定要**心平气和**，保持**工作的连贯性**。（~~不做完一套不能睡觉？~~）

### 得出结论

- 通过可视化直接得出结论（描述、总结）
- 统计学（预测，P4阶段会学习）
- 机器学习算法（主要是用来做预测，课下可以学一学）

### 传达结果

撰写报告，和别人分享你的研究结果，所以一定要逻辑清晰、结论都要有根有据，让被分享者信服你的结论。

## Pandas在数据分析中的应用

### 准备

- 导入Pandas包

  ```python
  import pandas as pd
  ```

- 打开文件

  ```python
  #打开csv文件
  pd.read_csv('filename')
  #打开excel文件
  pd.read_excel('filename')
  #处理中文字符的tsv文件
  pd.read_csv('filename',sep = '\t',encoding = 'utf-8')
  ```

### 整理数据

- 查看数据集数据

  ```python
  #查看前五行
  df.head()
  #查看尾五行
  df.tail()
  #查看随机一行
  df.sample()
  ```

- 查看数据集信息

  ```python
  #查看数据集行数和列数
  df.shape
  #查看数据集信息（列名、数据类型、每列的数据量——可以看出数据缺失情况）
  df.info()
  #查看数据集基本统计信息
  df.describe()
  #查看数据集列名
  df.columns
  #查看数据集数据缺失情况 
  df.isnull().sum()
  #查看缺失列数据
  df[df['col_name'].isnull()]
  #查看数据集数据重复情况
  sum(df.duplicated())
  #查看重复数据
  df[df.duplicated()]
  #查看某列分类统计情况
  df['col_name'].value_counts()
  #查看某列唯一值
  df['col_name'].unique()
  #查看某列唯一值数量
  df['col_name'].nunique()
  #以某列对数据集进行排序
  df.sort_values(by = 'col_name',ascending = False)#False为由大至小
  ```

- 数据筛选

  ```python
  #提取某行
  df.iloc[row_index]
  df.loc['row_name']
  #提取某几行
  df.iloc[row_index_1:row_index_2]
  #提取某列
  df['col_name']
  #提取某几列
  df[['col_name_1','col_name_2']]
  #提取某行某列的值
  df.iloc[row_index,col_index]
  df.loc['row_name','col_name']
  #筛选某列中满足某条件的数据
  df[df['col_name'] == value]#等于某值的数据，同理满足所有比较运算符
  df.query('col_name == value')#代码效果同上
  df[(df['col_name_1'] >= value_1) & (df['col_name_2'] != value_2)]#与&，或|
  df.query('(col_name_1 >= value_lower) & (col_name_2 <= value_upper)')
  df.groupby('col_name')#按col_name列进行分组
  ```

- 清理数据

  ```python
  #删除某行
  df.drop(['row_name'],inplace = True)#若添加inplace = True，修改后的数据会覆盖原始数据
  #删除某列
  df.drop(['col_name'],axis = 1)
  #缺失值的处理
  df.fillna(mean_value)#替换缺失值
  df.dropna()#删除包含缺失值的行
  df.dropna(axis = 1, how = 'all')#只删除所有数据缺失的列
  #删除重复值
  drop_duplicates(inplace = True)
  #更改某行/列/位置数据
  用iloc或者loc直接替换修改即可
  #更改数据类型
  df['datetime_col'] = pd.to_datetime(df['datetime_col'])
  df['col_name'].astype(str)#还可以是int/float...
  #更改列名
  df.rename(columns={'A':'a', 'C':'c'}, inplace = True)
  ```

  > 如何处理缺失值呢？这就要根据确实数据的情况而定了，是直接删除？还是暴力平均值替换？还是分类之后再用平均值替换？还是用一些什么其他的方法，全靠你去把握了。可以看一看**Python Data Science**这本书中的[**Handling Missing Data**](https://jakevdp.github.io/PythonDataScienceHandbook/03.04-missing-values.html)章节，你肯定会有所收获的。

- 合并数据(merge、concat、join、append)

  因为这里比较繁琐，而且讲起来会用到很多图表，所以进行单独讲解，链接→[每周导学-第六周导学-Pandas数据融合](http://www.capallen.top/dand-vip/2018/08/21/%E7%AC%AC%E5%85%AD%E5%91%A8-2-%E6%95%B0%E6%8D%AE%E8%9E%8D%E5%90%88/)

### 可视化

我会将Pandas的可视化部分与**matplotlib.pyplot**的可视化和**seaborn/ggplot**等可视化包放在下周的导学中。

### 导出数据

```python
#导出csv文件
df.to_csv('filename.csv',index = False)
#导出中文字符的excel文件
df.to_excel('filename.xlsx',index = False,encoding = 'utf-8-sig')
```

> Tip:[utf-8与utf-8-sig 两种编码格式区别](https://blog.csdn.net/u012965373/article/details/52680787)

# 项目相关

P3的项目需要你完完整整得过一遍数据分析的过程，所以呢，单独的某一个数据集肯定满足不了大家，贴心的Udacity给大家准备了几个数据集备选，戳[数据集预览](https://github.com/udacity/new-dand-basic-china/blob/master/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E5%85%A5%E9%97%A8/%E9%A1%B9%E7%9B%AE-%E6%8E%A2%E7%B4%A2%E6%95%B0%E6%8D%AE%E9%9B%86/%E6%8E%A2%E7%B4%A2%E6%95%B0%E6%8D%AE%E9%9B%86%20-%20%E5%A4%87%E9%80%89%E6%95%B0%E6%8D%AE%E9%9B%86.md)，挑一个自己感兴趣的先~